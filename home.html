import hashlib
import requests
import time
import aiohttp
import asyncio
import digitalio
import board
import st7789

# LCD setup for Waveshare 1.69-inch display
cs_pin = digitalio.DigitalInOut(board.CE0)
dc_pin = digitalio.DigitalInOut(board.D25)
reset_pin = digitalio.DigitalInOut(board.D24)
BL_pin = digitalio.DigitalInOut(board.D26)  # Backlight
BL_pin.switch_to_output()

spi = board.SPI()
lcd = st7789.ST7789(
    spi,
    240, 280,
    cs=cs_pin,
    dc=dc_pin,
    rst=reset_pin,
    baudrate=64000000
)

# Initialize the display
lcd.init()
lcd.fill(st7789.BLACK)  # Clear the screen

# Cache dictionary for storing OCR results
cache = {}

def compute_file_hash(filename):
    with open(filename, 'rb') as f:
        file_hash = hashlib.md5(f.read()).hexdigest()
    return file_hash

def ocr_space_file_with_cache(filename, api_key):
    file_hash = compute_file_hash(filename)
    if file_hash in cache:
        print("Returning cached result")
        return cache[file_hash]
    result = ocr_space_file(filename, api_key)
    cache[file_hash] = result
    return result

def ocr_space_file(filename, api_key):
    url = 'https://api.ocr.space/parse/image'
    payload = {'isOverlayRequired': False, 'apikey': api_key, 'language': 'eng'}
    with open(filename, 'rb') as f:
        files = {'file': f}
        response = requests.post(url, files=files, data=payload)
    return response.json()

def send_to_lcd(text):
    lcd.fill(st7789.BLACK)  # Clear display to black
    lines = textwrap.wrap(text, width=30)  # Wrap text to fit the display
    y = 10
    for line in lines:
        lcd.text(line, 10, y, st7789.WHITE)
        y += 10  # Adjust y increment based on font size and spacing

async def ask_chatgpt_async(question, openai_api_key):
    url = 'https://api.openai.com/v1/completions'
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {openai_api_key}'
    }
    payload = {
        'model': 'gpt-3.5-turbo',
        'prompt': question,
        'max_tokens': 150
    }
    async with aiohttp.ClientSession() as session:
        async with session.post(url, json=payload, headers=headers) as response:
            return await response.json()

def main(filename, ocr_api_key, openai_api_key):
    ocr_result = ocr_space_file_with_cache(filename, ocr_api_key)
    print("OCR Result:", ocr_result)
    if 'ParsedResults' in ocr_result and len(ocr_result['ParsedResults']) > 0:
        raw_text = ocr_result['ParsedResults'][0].get('ParsedText', '')
        loop = asyncio.get_event_loop()
        chatgpt_response = loop.run_until_complete(ask_chatgpt_async(raw_text, openai_api_key))
        if 'choices' in chatgpt_response and len(chatgpt_response['choices']) > 0:
            response_text = chatgpt_response['choices'][0]['text'].strip()
            send_to_lcd(response_text)
            print("Displayed on LCD:", response_text)
        else:
            print("No response from ChatGPT or error")
    else:
        print("No text found or error in OCR")

if __name__ == "__main__":
    filename = 'path_to_your_image.jpg'
    ocr_api_key = "Your_OCR_API_Key"
    openai_api_key = "Your_OpenAI_API_Key"
    main(filename, ocr_api_key, openai_api_key)
